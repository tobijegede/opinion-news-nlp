{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get To The Correct Landing Page & Pull Site HTML Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdc_newsroom_url = \"https://www.cdc.gov/media/releases/2020/archives.html\"\n",
    "\n",
    "#the specific cdc feed on COVID-19 \n",
    "cdc_newsroom_url = \"https://www.cdc.gov/media/dpk/diseases-and-conditions/coronavirus/coronavirus-2020.html\"\n",
    "\n",
    "#step 2: get to the landing page of the website\n",
    "landing_page = requests.get(cdc_newsroom_url)\n",
    "\n",
    "#step 3: convert page into html\n",
    "soup = BeautifulSoup(landing_page.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigate to the Collection of Press Releases\n",
    "\n",
    "Note: The data pulled from the CDC website comes specifically from the following tabs: PRESS RELEASES, TRANSCRIPTS, + STATEMENTS (and possibly one more tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release_feed = soup.find_all(\"div\", class_= \"pressrel\")  #this will include in\n",
    "\n",
    "## this feed includes the press releases that are in all of the tabs  on the website\n",
    "## CONTAINS CONTENT FROM THE TAB: PRESS RELEASES, TRANSCRIPTS, + STATEMENTS ON THE CDC'S WEBSITE\n",
    "#print(press_release_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Pertinent Transcript Information & Store Results in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom the below we need: 1. href (Transcript url), and item_pub date\\n<a class=\"item-title\" href=\"/media/releases/2022/p0331-youth-mental-health-covid-19.html\">New CDC data illuminate youth mental health threats during the COVID-19 pandemic</a> -\\n <span class=\"item-pubdate\">Thursday, March 31, 2022</span>\\n</li>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: gets all of the contents of each of the tabs (Advisories, Trasnricripts, etc)\n",
    "\n",
    "transcript_info = {} #key = air date, value is a dictionary with the (transcript url, guest, and text of the show)\n",
    "starting_url = \"https://www.cdc.gov\"\n",
    "\n",
    "for tab in press_release_feed:\n",
    "   \n",
    "    item_titles = tab.find_all(\"a\", class_=\"item-title\")\n",
    "    pub_dates = tab.find_all(\"span\", class_=\"item-pubdate\")\n",
    " \n",
    "    for (title, date) in zip(item_titles, pub_dates):\n",
    "        transcript_url = starting_url + title[\"href\"]\n",
    "        date_text = date.text\n",
    "        title_text = title.text\n",
    "        #print(date_text, title_text, transcript_url, \"\\n\")\n",
    "\n",
    "        #add the information to the transcript info to the dictionary\n",
    "        transcript_info[date_text] =  {\"transcript_url\": transcript_url,\n",
    "                                        \"transcript_title\": title_text }\n",
    "\n",
    "#    # pub_dates = tab.find(\"span\", class_=\"item_pubdate\") #.text\n",
    "  #  print(pub_dates)\n",
    "   \n",
    "# <ul id=\"Ul1\"> -- this ID is unique for each of the tabs\n",
    "\n",
    "#need the website associated with each of the items, as well as the daa\n",
    "'''\n",
    "From the below we need: 1. href (Transcript url), and item_pub date\n",
    "<a class=\"item-title\" href=\"/media/releases/2022/p0331-youth-mental-health-covid-19.html\">New CDC data illuminate youth mental health threats during the COVID-19 pandemic</a> -\n",
    " <span class=\"item-pubdate\">Thursday, March 31, 2022</span>\n",
    "</li>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript_url': 'https://www.cdc.gov/media/releases/2021/a0727-covid-update.html',\n",
       " 'transcript_title': 'CDC MEDIA TELEBRIEFING: Update on COVID-19'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(transcript_info.values())[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Text of the Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3492921570.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [17]\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Include the following items:\n",
    "\"Media Telebriefing\"\n",
    "\"Transcript\"\n",
    "\"Statement\"\n",
    "\n",
    "\n",
    "'''\n",
    "num_transcripts = 0 \n",
    "transcript_words = [\"Media Telebriefing\", \"Transcript\", \"Statement\"]\n",
    "\n",
    "for pub_date in list(transcript_info.keys()):\n",
    "      # print(pub_date)\n",
    "       #get needed information\n",
    "       transcript_url = transcript_info[pub_date][\"transcript_url\"]\n",
    "       transcript_title = transcript_info[pub_date][\"transcript_title\"]\n",
    "\n",
    "       if any(word in transcript_title for word in transcript_words): #only include the transcripts\n",
    "              \n",
    "              num_transcripts += 1\n",
    "\n",
    "              if num_transcripts != 33: #there seems to be an issue with the 33rd URL -- so this is the workaround bc it's unclear why its not working (when I separately isolate this URL and put it in Google Chrome, it works)\n",
    "                     #print(num_transcripts)\n",
    "\n",
    "                     #go to the url\n",
    "                     #show_page = requests.get(transcript_url)\n",
    "\n",
    "       #        #convert the page into a soup object\n",
    "       #        show_soup =  BeautifulSoup(show_page.content, \"html.parser\")\n",
    "\n",
    "  \n",
    "       #        #get the content of the transcript = <div class= \"card-body bg-white\">\n",
    "       #        transcript_text = show_soup.find(class_=\"card-body bg-white\").text\n",
    "\n",
    "       #        #add the transcript text to the dictionary\n",
    "       #        transcript_info[pub_date][\"transcript_text\"] = transcript_text\n",
    "       #        #print(transcript_title, transcript_url, transcript_text)\n",
    "\n",
    "       # list_pub_date = pub_date.split()\n",
    "       # print(list_pub_date)\n",
    "             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 transcripts from late 2019 to 2022 from the CDC on COVID-19.\n"
     ]
    }
   ],
   "source": [
    "#How many transcripts are there?\n",
    "\n",
    "print(\"There are {} transcripts from late 2019 to 2022 from the CDC on COVID-19.\".format(num_transcripts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function \n",
    "\n",
    "def get_transcript(folder_name):\n",
    "    '''\n",
    "    Input: folder_name (string)  (no need for search URL here because it does change)\n",
    "    Output: None (does not return anything but writes the text of the transript to a file)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # ----------  GET TO THE WEBISTE & EXTRACT HTML\n",
    "    #store the cdc url.\n",
    "    cdc_newsroom_url = \"https://www.cdc.gov/media/dpk/diseases-and-conditions/coronavirus/coronavirus-2020.html\"\n",
    "\n",
    "    #step 2: get to the landing page of the website\n",
    "    landing_page = requests.get(cdc_newsroom_url)\n",
    "\n",
    "    #step 3: convert page into html\n",
    "    soup = BeautifulSoup(landing_page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "    #------ PARSE THROUGH THE HTML\n",
    "    #step 1: gets all of the contents of each of the tabs (Advisories, Trasnricripts, etc)\n",
    "\n",
    "    press_release_feed = soup.find_all(\"div\", class_= \"pressrel\")  #this will include in\n",
    "\n",
    "    transcript_info = {} #key = air date, value is a dictionary with the (transcript url, guest, and text of the show)\n",
    "    starting_url = \"https://www.cdc.gov\"\n",
    "\n",
    "    for tab in press_release_feed:\n",
    "\n",
    "    \n",
    "        item_titles = tab.find_all(\"a\", class_=\"item-title\")\n",
    "        pub_dates = tab.find_all(\"span\", class_=\"item-pubdate\")\n",
    "    \n",
    "        for (title, date) in zip(item_titles, pub_dates):\n",
    "            transcript_url = starting_url + title[\"href\"]\n",
    "            date_text = date.text\n",
    "            title_text = title.text\n",
    "            #print(date_text, title_text, transcript_url, \"\\n\")\n",
    "\n",
    "            #add the information to the transcript info to the dictionary\n",
    "            transcript_info[date_text] =  {\"transcript_url\": transcript_url,\n",
    "                                            \"transcript_title\": title_text }\n",
    "\n",
    "    \n",
    "    # --- GET THE ACTUAL TRANSCRIPT TEXT\n",
    "\n",
    "    #step 7: iterate through all of the pub dates to get the actual text of the transcript + write the text to a file \n",
    "\n",
    "    transcript_words = [\"Media Telebriefing\", \"Transcript\", \"Statement\"] #only want to include transcripts\n",
    "    num_transcripts = 0 \n",
    "\n",
    "    for pub_date in list(transcript_info.keys()):\n",
    "       #get needed information\n",
    "       transcript_url = transcript_info[pub_date][\"transcript_url\"]\n",
    "       transcript_title = transcript_info[pub_date][\"transcript_title\"]\n",
    "\n",
    "       issue_url = \"https://www.cdc.gov/media/releases/2020/t0229-COVID-19-update.html\"\n",
    "\n",
    "       if any(word in transcript_title for word in transcript_words): #only include the transcripts\n",
    "           num_transcripts += 1\n",
    "           if num_transcripts != 33: #there seems to be an issue with the 33rd URL -- so this is the workaround bc it's unclear why its not working (when I separately isolate this URL and put it in Google Chrome, it works)\n",
    "\n",
    "                #go to the url\n",
    "                show_page = requests.get(transcript_url)\n",
    "\n",
    "                #convert the page into a soup object\n",
    "                show_soup =  BeautifulSoup(show_page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "                #get the content of the transcript = <div class= \"card-body bg-white\">\n",
    "                transcript_text = show_soup.find(class_=\"card-body bg-white\").text\n",
    "\n",
    "                #add the transcript text to the dictionary\n",
    "                transcript_info[pub_date][\"transcript_text\"] = transcript_text\n",
    "                #print(transcript_title, transcript_url, transcript_text)\n",
    "\n",
    "\n",
    "\n",
    "        # --- NOW THAT WE HAVE THE ACTUAL TEXT OF THE TRANSCRIPT, EXPORT THIS TO A TEXT FILE\n",
    "            \n",
    "                #create a file name + output file path\n",
    "                list_pub_date = pub_date.split()\n",
    "\n",
    "\n",
    "                filename = list_pub_date[1] + \"_\" + list_pub_date[2][:-1] + \"_\" + list_pub_date[3] + \"_\" + \"cdc\" + \"_\" + \"transcript.txt\"\n",
    "                repo_path = os.path.dirname(os.getcwd())\n",
    "                output_path = os.path.join(repo_path, \"data\", \"01-raw\", folder_name, filename)\n",
    "\n",
    "                #print(output_path)\n",
    "\n",
    "                #export the file\n",
    "                with open(output_path,\"w\") as f:\n",
    "                    f.write(transcript_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the function in the above cell to get the CDC transcripts\n",
    "folder_name = \"cdc_press_releases\"\n",
    "\n",
    "get_transcript(folder_name) #running to a slight issue here!  with the below URL\n",
    "# //www.cdc.gov/media/releases/2020/t0229-COVID-19-update.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
